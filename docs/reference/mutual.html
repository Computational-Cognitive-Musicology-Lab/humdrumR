<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="The mutual information is a measure of how statistically
dependent two variables are: in information theory terms, how much information about one variable
is learned from observing other variable(s).
The overall mutual information can be calculated using mutual() (analogous to entropy()),
while the point-wise mutual information can be calculated using pmutual() (analogous to info())."><title>Calculate mutual information between variables — mutual • humdrumR</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><meta property="og:title" content="Calculate mutual information between variables — mutual"><meta property="og:description" content="The mutual information is a measure of how statistically
dependent two variables are: in information theory terms, how much information about one variable
is learned from observing other variable(s).
The overall mutual information can be calculated using mutual() (analogous to entropy()),
while the point-wise mutual information can be calculated using pmutual() (analogous to info())."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary" data-bs-theme="dark"><div class="container">
    <a href="https://gatech.edu" class="external-link"><img src="gt-logo.svg" alt="Georgia Tech" style="height:50px; padding-right:20px;"></a> <a href="https://ccml.gtcmt.gatech.edu" class="external-link"><img src="CCMLbanner.png" alt="CCMLab" style="height:80px; padding-right:20px;"></a>
    <a class="navbar-brand me-2" href="../index.html">humdrumR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.7.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../news/index.html">News</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Basics</h6>
    <a class="dropdown-item" href="../articles/GettingStarted.html">Getting started with humdrumR</a>
    <a class="dropdown-item" href="../articles/DataFields.html">HumdrumR Data Fields</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>R/Background</h6>
    <a class="dropdown-item" href="../articles/HumdrumSyntax.html">The humdrum syntax</a>
    <a class="dropdown-item" href="../articles/RPrimer.html">An R primer for humdrumR users</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Data prep</h6>
    <a class="dropdown-item" href="../articles/ReadWrite.html">Reading and writing humdrum data</a>
    <a class="dropdown-item" href="../articles/ComplexSyntax.html">Complex humdrum syntax</a>
    <a class="dropdown-item" href="../articles/Reshaping.html">Shaping humdrum data</a>
    <a class="dropdown-item" href="../articles/Filtering.html">Filtering humdrum data</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Analysis</h6>
    <a class="dropdown-item" href="../articles/Summary.html">Getting to know your humdrum data</a>
    <a class="dropdown-item" href="../articles/Grouping.html">Grouping humdrum data</a>
    <a class="dropdown-item" href="../articles/Context.html">Contextualizing humdrum data</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Musical tools</h6>
    <a class="dropdown-item" href="../articles/PitchAndTonality.html">Pitch and tonality in humdrumR</a>
    <a class="dropdown-item" href="../articles/RhythmAndMeter.html">Time, rhythm, and meter in humdrumR</a>
    <a class="dropdown-item" href="../articles/KeysAndChord.html">Diatonic and tertian sets in humdrumR</a>
  </div>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://ccml.music.gatech.edu/humdrumR">GUI</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/Computational-Cognitive-Musicology-Lab/humdrumR/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Calculate mutual information between variables</h1>
      <small class="dont-index">Source: <a href="https://github.com/Computational-Cognitive-Musicology-Lab/humdrumR/blob/HEAD/R/Distributions.R" class="external-link"><code>R/Distributions.R</code></a></small>
      <div class="d-none name"><code>mutual.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>The <a href="https://en.wikipedia.org/wiki/Mutual_information" class="external-link">mutual information</a> is a measure of how statistically
dependent two variables are: in information theory terms, how much information about one variable
is learned from observing other variable(s).
The overall mutual information can be calculated using <code>mutual()</code> (analogous to <code><a href="entropy.html">entropy()</a></code>),
while the point-wise mutual information can be calculated using <code>pmutual()</code> (analogous to <code><a href="entropy.html">info()</a></code>).</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">mutual</span><span class="op">(</span><span class="va">...</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for probability</span></span>
<span><span class="fu">mutual</span><span class="op">(</span><span class="va">x</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for default</span></span>
<span><span class="fu">mutual</span><span class="op">(</span><span class="va">...</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for probability</span></span>
<span><span class="fu">mutual</span><span class="op">(</span><span class="va">x</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for default</span></span>
<span><span class="fu">mutual</span><span class="op">(</span><span class="va">...</span>, base <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">pmutual</span><span class="op">(</span></span>
<span>  <span class="va">...</span>,</span>
<span>  <span class="va">model</span>,</span>
<span>  base <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  condition <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  na.rm <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  .drop <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  binArgs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Mutual information is a property of probability distributions over two or more variables.
HumdrumR's <code>count()</code> and <code><a href="pdist.html">pdist()</a></code> methods (or R's standard <code><a href="distributions.html">table()</a></code> function) can be used calculate empirical
distributions over atomic data, and we can then calculate their mutual information.</p>
<p>The <code>mutual()</code> and <code>pmutual()</code> functions are called just like <code><a href="entropy.html">entropy()</a></code> and <code><a href="entropy.html">info()</a></code>.
<code>mutual()</code> can be provided a <a href="distributions.html">table</a> of distribution (from <code><a href="pdist.html">pdist()</a></code>), or can be directly provided two or more
atomic vectors, which are simply passed to <code><a href="pdist.html">pdist()</a></code>; in other words, <code>mutual(x, y) == mutual(pdist(x, y))</code>.
<code>pmutual()</code>, like <code><a href="entropy.html">info()</a></code>, can only be passed raw atomic vectors, like <code>pmutual(x, y)</code>.
Note that, unlike the entropy functions, the mutual information functions will throw an error if you only
provide them a single variable.</p>
    </div>
    <div class="section level2">
    <h2 id="further-explanation">Further explanation<a class="anchor" aria-label="anchor" href="#further-explanation"></a></h2>
    


<p>If two (or more) variables are statistically independent, their joint entropy will be the sum of their
independent entropies.</p>
<p>$$
H(X, Y) = H(X) + H(Y)
$$</p>
<p>However, if they are not independent, their joint entropy will be less than the summed independent entropies.
The mutual information is the difference between the summed independent entropies and their actual observed
joint entropy.</p>
<p>$$
I(X,Y) = (H(X) + H(Y)) - H(X,Y)
$$</p>
<p>For the point-wise mutual information, we get a single value for each data observation.
The value represents the difference between the observed joint likelihood of each observation
and the value we'd expect if the variable were independent.
For example, consider the variables binary variables "person likes heavy metal" ($P(metal)$) and "person plays electric guitar" ($P(guitar)$).
Imagine that $P(metal) = .05$ and $P(guitar) = .1$.
If these two variables are independent, we'd expect that the joint probability of liking heavy metal
<em>and</em> playing guitar would be $P(metal, guitar) = .05 * .1 = .005$ (one out of 200 people).
However, on measuring some data, we might find that actually one in fifty people like metal and play guitar ($P(metal, guitar) = .02$).
This means that the combination of liking metal and playing guitar is $\frac.02.005 = 4$ times more likely than we'd expect
if they were independent.
This would translate to a point-wise mutual information of (using default base-2 "bits") $+2$.
The overall mutual information is the average over all the point-wise values (including other combinations, like heavy metal fans who don't play guitar).</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p>The HumdrumR <a href="information.html">information theory</a> overview.</p>
<p>Other Information theory functions: 
<code><a href="entropy_by.html">entropy_by</a>()</code>,
<code><a href="entropy.html">entropy</a>()</code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">guitar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span>, <span class="cn">F</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">metal</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>, <span class="cn">T</span>,<span class="cn">T</span>,<span class="cn">T</span>,<span class="cn">F</span>,<span class="cn">F</span>,<span class="cn">T</span>,<span class="cn">T</span>,<span class="cn">F</span>,<span class="cn">F</span>,<span class="cn">F</span>,<span class="cn">F</span>,<span class="cn">F</span>,<span class="cn">F</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu">mutual</span><span class="op">(</span><span class="fu"><a href="pdist.html">pdist</a></span><span class="op">(</span><span class="va">guitar</span>, <span class="va">metal</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I(guitar;metal) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       0.1887219 </span>
<span class="r-in"><span><span class="fu">mutual</span><span class="op">(</span><span class="va">guitar</span>, <span class="va">metal</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> I(guitar;metal) </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>       0.1887219 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu">pmutual</span><span class="op">(</span><span class="va">guitar</span>, <span class="va">metal</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1]  0.5849625  0.5849625  0.5849625  0.5849625  0.5849625  0.5849625</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [7] -1.0000000 -1.0000000 -1.0000000 -1.0000000  0.5849625  0.5849625</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13]  0.5849625  0.5849625  0.5849625  0.5849625</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Nathaniel Condit-Schultz, Claire Arthur.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Georgia Tech, <a href="https://music.gatech.edu" class="external-link">School of Music</a>, <a href="https://ccml.gtcmt.gatech.edu" class="external-link">Computational and Cognitive Musicology Lab</a></p>
</div>

    </footer></div>

  

  

  </body></html>

