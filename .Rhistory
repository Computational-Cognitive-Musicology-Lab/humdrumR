else{
return(".")
# return null token if no match
}
}
numbers <- 1:nrow(save2)
# number of rows to go through in apply function
numbers <- as.data.frame(numbers)
# save as data frame so the apply function can work properly
saveNew <- apply(numbers, 1, function(x){newFunction(save2,x)})
# apply function to paste row values to each word
saveNew <- as.data.frame(saveNew)
# save as data frame for parsing below
saveNew <- saveNew[!grepl(".", saveNew$saveNew, fixed = TRUE),]
# save values that are not null tokens
finalData <- numbers
# final data will have size nrows
finalWordsLength <- 1:nrow(saveWords)
# final words length will have size of total words
finalWordsLength <- as.data.frame(finalWordsLength)
# save as data frame for use in apply function
saveNewDataFrame <- as.data.frame(saveNew)
# save as data frame for use in apply function
finalData <- apply(finalWordsLength, 1, function(x){newFunction2(saveNewDataFrame, x)})
# apply function to replace words with row values
finalDataComplete <- apply(numbers, 1, function(x){newFunction4(x, finalData, saveWords)})
# apply function to match row numbers of words with corresponding words
data <- (unlist(finalDataComplete))
# unlist to save as character vector
}
return(data)
}
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','self'))
text <- function(data, nullTokens = TRUE){
# print(silbeFormat(as.data.frame(data)))
if(nullTokens == FALSE){
# if the user does not want null tokens to replace instances of syllables occurring after the first syllable of a multi-syllable word
data <- as.data.frame(data)
# transform character vector to data frame
data <- toString(data[,1])
# transform character vector to string *seems as though we might not need to transform to data frame above then*
data <- stringr::str_replace_all(data, "-, -", "")
# remove all instances of -, -, which represents a space between two syllables which when combined form a word
data <- stringr::str_replace_all(data, ",", "")
# remove all instances of , which occur after every word except the last one
data <- as.list(stringr::strsplit(data, '\\s+')[[1]])
# get all of the words as a list
transpose1 <- t(data)
transpose2 <- t(transpose1)
data <- as.character(transpose2)
# transform the data further to get desired character vector
}
else{
# if the user does want null tokens to replace instances of syllables occurring after the first syllable of a multi-syllable word
wordAddSpace <- function(value){
# create function to be used later which will either print TRUE or FALSE, depending on if there is a - at the beginning of a syllable
# when we split up syllables from multi-syllable words, some will either have - at the beginning or - at the end.
if(substr(value,1,1) == "-"){
return(TRUE)
}
else{
return(FALSE)
}
}
replaceWithNullToken <- function(booleanValue){
# create a function for replacing cells with null tokens, to be used in an apply function later
if(booleanValue == TRUE){
return(".")
}
else{
return("word")
# return "word" for identification/logic purposes later
}
}
saveData <- data
# save current character vector ("data") in a new variable to be used later
data <- as.data.frame(data)
# transform character vector ("data") into a data frame
save <- apply(data, 1, function(x){wordAddSpace(x)})
# for each row value in the data frame (which in this case corresponds to a syllable) determine if this is a row that needs to be deleted in the future by returning TRUE for that
# index
save <- as.data.frame(save)
# go through and if true then add space below
save2 <- apply(save, 1, function(x){replaceWithNullToken(x)})
# save a vector with null tokens in the correct spots, and the spots that will be filled with words are each labeled "word"
save2 <- as.data.frame(save2)
# transform to data frame
saveWords <- text(saveData, nullTokens = FALSE)
# run this text function with null tokens = false to get the full words of the character vector
saveWords <- as.data.frame(saveWords)
# transform these words into a data frame
newFunction <- function(dataValue, rowValue){
rowValueToString <- toString(rowValue)
# save given row value as a string to be used below
dataValue[rowValue,1] <- paste(dataValue[rowValue,1], rowValueToString, sep = "")
# paste the row value to each word for parsing and reading into final data frame/character vector later
return(dataValue[rowValue,1])
}
newFunction2 <- function(findRowValues, iteration){
getRowValueFinal <- sub("word*", "", findRowValues[iteration,1])
# based on the row values of each word, replace each "word" with the row value corresponding to a word
return(getRowValueFinal)
}
newFunction4 <- function(iterate, final, wordsArray){
iterateToString <- toString(iterate)
# save iteration value as a string for comparison to what is in the data frame/character vector
if(iterateToString %in% final){
# comparison for each cell
return(wordsArray[match(iterate,final),1])
# return corresponding word
}
else{
return(".")
# return null token if no match
}
}
numbers <- 1:nrow(save2)
# number of rows to go through in apply function
numbers <- as.data.frame(numbers)
# save as data frame so the apply function can work properly
saveNew <- apply(numbers, 1, function(x){newFunction(save2,x)})
# apply function to paste row values to each word
saveNew <- as.data.frame(saveNew)
# save as data frame for parsing below
saveNew <- saveNew[!grepl(".", saveNew$saveNew, fixed = TRUE),]
# save values that are not null tokens
finalData <- numbers
# final data will have size nrows
finalWordsLength <- 1:nrow(saveWords)
# final words length will have size of total words
finalWordsLength <- as.data.frame(finalWordsLength)
# save as data frame for use in apply function
saveNewDataFrame <- as.data.frame(saveNew)
# save as data frame for use in apply function
finalData <- apply(finalWordsLength, 1, function(x){newFunction2(saveNewDataFrame, x)})
# apply function to replace words with row values
finalDataComplete <- apply(numbers, 1, function(x){newFunction4(x, finalData, saveWords)})
# apply function to match row numbers of words with corresponding words
data <- (unlist(finalDataComplete))
# unlist to save as character vector
}
return(data)
}
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','self'))
strssplit
strsplit
text <- function(data, nullTokens = TRUE){
# print(silbeFormat(as.data.frame(data)))
if(nullTokens == FALSE){
# if the user does not want null tokens to replace instances of syllables occurring after the first syllable of a multi-syllable word
data <- as.data.frame(data)
# transform character vector to data frame
data <- toString(data[,1])
# transform character vector to string *seems as though we might not need to transform to data frame above then*
data <- stringr::str_replace_all(data, "-, -", "")
# remove all instances of -, -, which represents a space between two syllables which when combined form a word
data <- stringr::str_replace_all(data, ",", "")
# remove all instances of , which occur after every word except the last one
data <- as.list(strsplit(data, '\\s+')[[1]])
# get all of the words as a list
transpose1 <- t(data)
transpose2 <- t(transpose1)
data <- as.character(transpose2)
# transform the data further to get desired character vector
}
else{
# if the user does want null tokens to replace instances of syllables occurring after the first syllable of a multi-syllable word
wordAddSpace <- function(value){
# create function to be used later which will either print TRUE or FALSE, depending on if there is a - at the beginning of a syllable
# when we split up syllables from multi-syllable words, some will either have - at the beginning or - at the end.
if(substr(value,1,1) == "-"){
return(TRUE)
}
else{
return(FALSE)
}
}
replaceWithNullToken <- function(booleanValue){
# create a function for replacing cells with null tokens, to be used in an apply function later
if(booleanValue == TRUE){
return(".")
}
else{
return("word")
# return "word" for identification/logic purposes later
}
}
saveData <- data
# save current character vector ("data") in a new variable to be used later
data <- as.data.frame(data)
# transform character vector ("data") into a data frame
save <- apply(data, 1, function(x){wordAddSpace(x)})
# for each row value in the data frame (which in this case corresponds to a syllable) determine if this is a row that needs to be deleted in the future by returning TRUE for that
# index
save <- as.data.frame(save)
# go through and if true then add space below
save2 <- apply(save, 1, function(x){replaceWithNullToken(x)})
# save a vector with null tokens in the correct spots, and the spots that will be filled with words are each labeled "word"
save2 <- as.data.frame(save2)
# transform to data frame
saveWords <- text(saveData, nullTokens = FALSE)
# run this text function with null tokens = false to get the full words of the character vector
saveWords <- as.data.frame(saveWords)
# transform these words into a data frame
newFunction <- function(dataValue, rowValue){
rowValueToString <- toString(rowValue)
# save given row value as a string to be used below
dataValue[rowValue,1] <- paste(dataValue[rowValue,1], rowValueToString, sep = "")
# paste the row value to each word for parsing and reading into final data frame/character vector later
return(dataValue[rowValue,1])
}
newFunction2 <- function(findRowValues, iteration){
getRowValueFinal <- sub("word*", "", findRowValues[iteration,1])
# based on the row values of each word, replace each "word" with the row value corresponding to a word
return(getRowValueFinal)
}
newFunction4 <- function(iterate, final, wordsArray){
iterateToString <- toString(iterate)
# save iteration value as a string for comparison to what is in the data frame/character vector
if(iterateToString %in% final){
# comparison for each cell
return(wordsArray[match(iterate,final),1])
# return corresponding word
}
else{
return(".")
# return null token if no match
}
}
numbers <- 1:nrow(save2)
# number of rows to go through in apply function
numbers <- as.data.frame(numbers)
# save as data frame so the apply function can work properly
saveNew <- apply(numbers, 1, function(x){newFunction(save2,x)})
# apply function to paste row values to each word
saveNew <- as.data.frame(saveNew)
# save as data frame for parsing below
saveNew <- saveNew[!grepl(".", saveNew$saveNew, fixed = TRUE),]
# save values that are not null tokens
finalData <- numbers
# final data will have size nrows
finalWordsLength <- 1:nrow(saveWords)
# final words length will have size of total words
finalWordsLength <- as.data.frame(finalWordsLength)
# save as data frame for use in apply function
saveNewDataFrame <- as.data.frame(saveNew)
# save as data frame for use in apply function
finalData <- apply(finalWordsLength, 1, function(x){newFunction2(saveNewDataFrame, x)})
# apply function to replace words with row values
finalDataComplete <- apply(numbers, 1, function(x){newFunction4(x, finalData, saveWords)})
# apply function to match row numbers of words with corresponding words
data <- (unlist(finalDataComplete))
# unlist to save as character vector
}
return(data)
}
strsplit
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','self'))
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','-self'))
printSilbeFormat <- function(keepSilbeOutput){
reverse <- function(string, index, replacement){
stringi::stri_sub_replace_all(string, from = index, to = index-1, replacement = replacement)
}
# the above function is where the bijection occurs
save_index <- as.vector(keepSilbeOutput[[2]])
# save indices based on input
values <- toString(keepSilbeOutput[[1]])
# convert character vector to string for stringr usage
values2 <- str_replace_all(values, "-, -", "")
values3 <- str_replace_all(values2, ",", "")
# get just words with spaces in between each
reverseSave <- reverse(values3, save_index, "- -")
# use reverse function to input dashes in correct spots
word_count <- str_count(reverseSave, '\\w+')
# count number of words based on spaces
saveWords <- head(strsplit(reverseSave, split = "\ "), word_count)
# save words in list
saveWords2 <- unlist(saveWords)
return(saveWords2)
}
printSilbeFormat(textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','-self')))
printSilbeFormat(textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','-self'), nullTokens = F))
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','-self'))
textKeepSilbe(c('you', 'bet-','-ter', 'lose','your-','-self'))
text('you', 'bet-','-ter', 'lose','your-','-self'), nullTokens = F)
text(c('you', 'bet-','-ter', 'lose','your-','-self'), nullTokens = F)
text(c('you', 'bet-','-ter', 'lose','your-','-self'), nullTokens = T)
library(humdrumR)
readHumdrum('~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Humdrum/*hum') -> rs
pitch(c('1','7','6','b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
steps
semit(c('1','7','6','b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','^b3','1','b3','b5','4','b3','6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','^b3','1','b3','b5','4','b3','v6','1','b3','b7','1','b5','4'), Exclusive='deg')
semit(c('1','7','6','^b3','1','b3','b5','4','b3','v6','1','b3','b7','1','^b5','4'), Exclusive='deg')
rs$Token %hum>% c(~semit(Token, memoize=FALSE), where ~ Spine == 3, by ~ File) -> rs$Semit
octaves <- rs$Token %hum<% c(by ~ File,  recordtypes ~'L',
~{
oct <- as.numeric(gsub('.*=', '', grep('OCT', Token[Type =='L'], value = TRUE))) - 4
if(length(oct) > 0) data.frame(Oct=oct, file=File[1]) else c()
})
fixoct <- c(where ~ Spine == 3, by ~ File,
do ~ {
if (!File[1] %in% octaves$file) {
b <- Semit
} else {
oct <- octaves[File[1] == file, Oct]
first <- Semit[!is.na(Semit)][1]
offset <- -(first - (first %% 12)) + 12 * oct
b <- Semit + offset
}
b
})
rs$Token %hum>% fixoct -> rs$Semit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(Semit2), by ~ File) -> rs$DSemit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(tonalInterval(Token, memoize=FALSE)@Fifth), by ~ File) -> rs$DFifth
rs$Token %hum>% c(where ~ Spine == 3, do ~ sigma(ifelse(DFifth == -6 & seq_along(DFifth) > 1, DSemit2 + 12, DSemit2)), by ~ File) -> rs$Semit3
rs %hum<% c(by ~ File, ~mean(Semit3)) |> sort() |> plot()
rs[1] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[2] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[3] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[1] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[2] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[2]
rs[3] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[4] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[5] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[5]
rs %hum<% c(by ~ File, ~data.frame(File = File[1], Ran = diff(range(Semit3)))) -> ranges
ranges
setorder(ranges,Ran)
as.data.frame(ranges)
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[144]
setActiveFields(rs[44], c('Token', "Semit3"))
setActiveFields(rs[144], c('Token', "Semit3"))
setActiveFields(rs[144], c('Token', "Semit3"))
semit(c('1','7','4','7','1'),Exclusive='deg')
semit(c('1','7','^4','7','1'),Exclusive='deg')
semit(c('1','7','^4','6','5'),Exclusive='deg')
semit(c('1','7','^4','v6','5'),Exclusive='deg')
semit(c('1','b7','^4','v6','5'),Exclusive='deg')
semit(c('1','b7','^4','v6','5'),Key='E:',Exclusive='deg')
library(humdrumR)
readHumdrum('~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Humdrum/*hum') -> rs
rs$Token %hum>% c(~semit(Token, memoize=FALSE), where ~ Spine == 3, by ~ File) -> rs$Semit
octaves <- rs$Token %hum<% c(by ~ File,  recordtypes ~'L',
~{
oct <- as.numeric(gsub('.*=', '', grep('OCT', Token[Type =='L'], value = TRUE))) - 4
if(length(oct) > 0) data.frame(Oct=oct, file=File[1]) else c()
})
fixoct <- c(where ~ Spine == 3, by ~ File,
do ~ {
if (!File[1] %in% octaves$file) {
b <- Semit
} else {
oct <- octaves[File[1] == file, Oct]
first <- Semit[!is.na(Semit)][1]
offset <- -(first - (first %% 12)) + 12 * oct
b <- Semit + offset
}
b
})
rs$Token %hum>% fixoct -> rs$Semit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(Semit2), by ~ File) -> rs$DSemit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(tonalInterval(Token, memoize=FALSE)@Fifth), by ~ File) -> rs$DFifth
rs$Token %hum>% c(where ~ Spine == 3, do ~ sigma(ifelse(DFifth == -6 & seq_along(DFifth) > 1 & abs(DSemit2) == 6, DSemit2 + 12, DSemit2)), by ~ File) -> rs$Semit3
rs %hum<% c(by ~ File, ~mean(Semit3)) |> sort() |> plot()
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
setActiveFields(rs[144], c('Token', "Semit3"))
rs[144]$Token %hum<% ~. -> x
x
rs[144][[,3]]$Token %hum<% ~. -> x
x
semit(x, Exclusive='deg')
data.frame(x,semit(x, Exclusive='deg'))
semit(x, Exclusive='deg') |> plot()
semit(x, Exclusive='deg',Key='E:') |> plot()
rs[144] %humT% (do ~ plot(Semit2 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs$DSemit2
rs$DSemit2[144]
rs$DFifth[144]
setActive(rs[144], c('Token','DFifth','DSemit2', 'Semit3'))
setActiveFields(rs[144], c('Token','DFifth','DSemit2', 'Semit3'))
rs[144]
rs[144]
source("~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Scripts/ToKern.R")
as.data.frame(ranges)
rs[179]
rs[179] %humT% (do ~ plot(Semit2 ~ Record,ylim=c(-24,24), main = OTL[1]))
setActiveFields(rs[179], c('Token','DFifth','DSemit2', 'Semit3'))
devtools::load_all()
source("~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Scripts/ToKern.R")
setActiveFields(rs[179], c('Token','DFifth','DSemit2', 'Semit3'))
rs[179] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs %hum<% c(by ~ File, ~data.frame(File = File[1], Ran = diff(range(Semit3)))) -> ranges
setorder(ranges,Ran)
as.data.frame(ranges)
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
setActiveFields(rs[144], c('Token','DFifth','DSemit2', 'Semit3'))
rs[144]$Key
devtools::load_all()
library(humdrumR)
readHumdrum('~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Humdrum/*hum') -> rs
rs$Token %hum>% c(~semit(Token, memoize=FALSE), where ~ Spine == 3, by ~ File) -> rs$Semit
octaves <- rs$Token %hum<% c(by ~ File,  recordtypes ~'L',
~{
oct <- as.numeric(gsub('.*=', '', grep('OCT', Token[Type =='L'], value = TRUE))) - 4
if(length(oct) > 0) data.frame(Oct=oct, file=File[1]) else c()
})
fixoct <- c(where ~ Spine == 3, by ~ File,
do ~ {
if (!File[1] %in% octaves$file) {
b <- Semit
} else {
oct <- octaves[File[1] == file, Oct]
first <- Semit[!is.na(Semit)][1]
offset <- -(first - (first %% 12)) + 12 * oct
b <- Semit + offset
}
b
})
rs$Token %hum>% fixoct -> rs$Semit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(Semit2), by ~ File) -> rs$DSemit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(tonalInterval(Token, memoize=FALSE)@Fifth), by ~ File) -> rs$DFifth
rs$Token %hum>% c(where ~ Spine == 3, do ~ sigma(ifelse(DFifth == -6 & seq_along(DFifth) > 1 & (DSemit2 %% 12) == 6, DSemit2 + 12, DSemit2)), by ~ File) -> rs$Semit3
rs %hum<% c(by ~ File, ~mean(Semit3)) |> sort() |> plot()
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
for (i in c(-12,-5,0,7,12,19)) abline(i,0, lty='dashed')
rs[144]
rs[144]$Key
pitch('7', Exclusive='deg')
pitch('7', Exclusive='deg', Key='E:mix')
pitch('7', Exclusive='deg', Key='e:')
pitch('7', Exclusive='deg', Key='E:mix', parse(impliciSpecies=T))
pitch('7', Exclusive='deg', Key='E:mix', parse(implicitSpecies=T))
pitch('7', Exclusive='deg', Key='e:', parse(implicitSpecies=T))
source("~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Scripts/ToKern.R")
devtools::load_all()
source("~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Scripts/ToKern.R")
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), xlim=c(0,110), main = OTL[1]))
abline(-2)
abline(-20)
abline(-2,0)
abline(2,0)
abline(-10,0)
semit('7', Exclusive='deg', Key='E:', parse(implicitSpecies=T))
semit('7', Exclusive='deg', Key='E:mix', parse(implicitSpecies=T))
# library(humdrumR)
readHumdrum('~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Humdrum/*hum') -> rs
rs$Token %hum>% c(~semit(Token, memoize=FALSE, parse(implicitSpecies=TRUE)), where ~ Spine == 3, by ~ File) -> rs$Semit
octaves <- rs$Token %hum<% c(by ~ File,  recordtypes ~'L',
~{
oct <- as.numeric(gsub('.*=', '', grep('OCT', Token[Type =='L'], value = TRUE))) - 4
if(length(oct) > 0) data.frame(Oct=oct, file=File[1]) else c()
})
fixoct <- c(where ~ Spine == 3, by ~ File,
do ~ {
if (!File[1] %in% octaves$file) {
b <- Semit
} else {
oct <- octaves[File[1] == file, Oct]
first <- Semit[!is.na(Semit)][1]
offset <- -(first - (first %% 12)) + 12 * oct
b <- Semit + offset
}
b
})
rs$Token %hum>% fixoct -> rs$Semit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(Semit2), by ~ File) -> rs$DSemit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(tonalInterval(Token, memoize=FALSE)@Fifth), by ~ File) -> rs$DFifth
rs$Token %hum>% c(where ~ Spine == 3, do ~ sigma(ifelse(DFifth == -6 & seq_along(DFifth) > 1 & (DSemit2 %% 12) == 6, DSemit2 + 12, DSemit2)), by ~ File) -> rs$Semit3
rs %hum<% c(by ~ File, ~mean(Semit3)) |> sort() |> plot()
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), xlim=c(0,110), main = OTL[1]))
rs[144] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs %hum<% c(by ~ File, ~data.frame(File = File[1], Ran = diff(range(Semit3)))) -> ranges
setorder(ranges,Ran)
as.data.frame(ranges)
ranges[,plot(Ran)]
rs[133] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
rs[133] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), xlim=c(0,200),main = OTL[1]))
abline(3,0)
# library(humdrumR)
readHumdrum('~/Bridge/Research/Data/CoCoPops/RollingStoneCorpus/Humdrum/*hum') -> rs
rs$Token %hum>% c(~semit(Token, memoize=FALSE, parse(implicitSpecies=TRUE)), where ~ Spine == 3, by ~ File) -> rs$Semit
octaves <- rs$Token %hum<% c(by ~ File,  recordtypes ~'L',
~{
oct <- as.numeric(gsub('.*=', '', grep('OCT', Token[Type =='L'], value = TRUE))) - 4
if(length(oct) > 0) data.frame(Oct=oct, file=File[1]) else c()
})
fixoct <- c(where ~ Spine == 3, by ~ File,
do ~ {
if (!File[1] %in% octaves$file) {
b <- Semit
} else {
oct <- octaves[File[1] == file, Oct]
first <- Semit[!is.na(Semit)][1]
offset <- -(first - (first %% 12)) + 12 * oct
b <- Semit + offset
}
b
})
rs$Token %hum>% fixoct -> rs$Semit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(Semit2), by ~ File) -> rs$DSemit2
rs$Token %hum>% c(where ~ Spine == 3, do~delta(tonalInterval(Token, memoize=FALSE)@Fifth), by ~ File) -> rs$DFifth
rs$Token %hum>% c(where ~ Spine == 3, do ~ sigma(ifelse(DFifth == -6 & seq_along(DFifth) > 1 & (DSemit2 %% 12) == 6, DSemit2 + 12, DSemit2)), by ~ File) -> rs$Semit3
rs %hum<% c(by ~ File, ~mean(Semit3)) |> sort() |> plot()
rs[133] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), xlim=c(0,200),main = OTL[1]))
rs[133] %humT% (do ~ plot(Semit3 ~ Record,ylim=c(-24,24), main = OTL[1]))
